{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37kuHQGVajaY"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install super-gradients==3.1.0\n",
        "!pip install imutils\n",
        "!pip install roboflow\n",
        "!pip install pytube --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import models"
      ],
      "metadata": {
        "id": "u7BN8EBIbATB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91613b1-a12e-4a90-8089-9f0b57a50583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The console stream is logged into /root/sg_logs/console.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-05-22 11:12:20] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n",
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
            "[2023-05-22 11:12:26] WARNING - __init__.py - Failed to import pytorch_quantization\n",
            "[2023-05-22 11:12:26] WARNING - calibrator.py - Failed to import pytorch_quantization\n",
            "[2023-05-22 11:12:26] WARNING - export.py - Failed to import pytorch_quantization\n",
            "[2023-05-22 11:12:26] WARNING - selective_quantization_utils.py - Failed to import pytorch_quantization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import Trainer\n",
        "\n",
        "CHECKPOINT_DIR = '/content/checkpoints'\n",
        "trainer = Trainer(experiment_name='/content/nas_l_run', ckpt_root_dir=CHECKPOINT_DIR)"
      ],
      "metadata": {
        "id": "0aqwBNvybDTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import dataloaders\n",
        "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train, coco_detection_yolo_format_val"
      ],
      "metadata": {
        "id": "ngWzyIREbIEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_params = {\n",
        "    'data_dir':'/content/drive/MyDrive/TATA_splitted',\n",
        "    'train_images_dir':'/content/drive/MyDrive/TATA_splitted/train/Images',\n",
        "    'train_labels_dir':'/content/drive/MyDrive/TATA_splitted/train/Labels',\n",
        "    'val_images_dir':'/content/drive/MyDrive/TATA_splitted/val/Images',\n",
        "    'val_labels_dir':'/content/drive/MyDrive/TATA_splitted/val/Labels',\n",
        "    'classes': ['tata_logo']\n",
        "}"
      ],
      "metadata": {
        "id": "5O2EX9YkbJB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_IBY-pAGbJE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from PIL import Image\n",
        "\n",
        "def is_valid_jpeg(file_path):\n",
        "    try:\n",
        "        img = Image.open(file_path)\n",
        "        img.verify()\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False"
      ],
      "metadata": {
        "id": "cbhk8PycMikU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "train_data = coco_detection_yolo_format_train(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['train_images_dir'],\n",
        "        'labels_dir': dataset_params['train_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size':16,\n",
        "        'num_workers':2\n",
        "    }\n",
        ")\n",
        "\n",
        "val_data = coco_detection_yolo_format_val(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['val_images_dir'],\n",
        "        'labels_dir': dataset_params['val_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size':16,\n",
        "        'num_workers':2\n",
        "    }\n",
        ")\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "5jb_S2kWNJfK",
        "outputId": "a876168e-b22b-4248-fc3b-44d28ae56d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-05-22 11:46:57] WARNING - yolo_format_detection.py - 1 images are note associated to any label file\n",
            "[2023-05-22 11:46:57] WARNING - yolo_format_detection.py - 1 label files are not associated to any image.\n",
            "[2023-05-22 11:46:57] WARNING - yolo_format_detection.py - As a consequence, 231/232 images and 231/232 label files will be used.\n",
            "Caching annotations:  48%|████▊     | 112/231 [00:00<00:00, 400.19it/s]"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imagesize/imagesize.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mbyte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                     \u001b[0;32mwhile\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                         \u001b[0mbyte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ord() expected a character, but string of length 0 found",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f166bed18178>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train_data = coco_detection_yolo_format_train(\n\u001b[0m\u001b[1;32m      4\u001b[0m     dataset_params={\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'data_dir'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/dataloaders/dataloaders.py\u001b[0m in \u001b[0;36mcoco_detection_yolo_format_train\u001b[0;34m(dataset_params, dataloader_params)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mregister_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOCO_DETECTION_YOLO_FORMAT_TRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcoco_detection_yolo_format_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_params\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_params\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     return get_data_loader(\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coco_detection_yolo_format_base_dataset_params\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mdataset_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYoloDarknetFormatDetectionDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/dataloaders/dataloaders.py\u001b[0m in \u001b[0;36mget_data_loader\u001b[0;34m(config_name, dataset_cls, train, dataset_params, dataloader_params)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mlocal_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_local_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mwait_for_the_master\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset_params\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/datasets/detection_datasets/yolo_format_detection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, images_dir, labels_dir, classes, class_ids_to_ignore, ignore_invalid_labels, show_all_warnings, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_fields\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"original_target_format\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXYXY_LABEL\u001b[0m  \u001b[0;31m# We convert yolo format (LABEL_CXCYWH) to Coco format (XYXY_LABEL) when loading the annotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_all_warnings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_all_warnings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/common/decorators/factory_decorator.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_assign_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/datasets/detection_datasets/detection_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, original_target_format, max_num_samples, cache, cache_dir, input_dim, transforms, all_classes_list, class_inclusion_list, ignore_empty_annotations, target_fields, output_fields, verbose, show_all_warnings)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_required_annotation_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"img_path\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"resized_img_shape\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/datasets/detection_datasets/detection_dataset.py\u001b[0m in \u001b[0;36m_cache_annotations\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mimg_annotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0mn_invalid_bbox\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimg_annotation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_invalid_labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/datasets/detection_datasets/yolo_format_detection.py\u001b[0m in \u001b[0;36m_load_annotation\u001b[0;34m(self, sample_id)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mlabel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_file_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mimage_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimagesize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mimage_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imagesize/imagesize.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>HH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid JPEG file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;31m# handle JPEG2000s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'\\x00\\x00\\x00\\x0cjP  \\r\\n\\x87\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid JPEG file"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCaching annotations:  69%|██████▉   | 159/231 [00:00<00:00, 420.47it/s]\rCaching annotations:  70%|██████▉   | 161/231 [00:00<00:00, 385.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import models\n",
        "model = models.get('yolo_nas_l', \n",
        "                   num_classes=len(dataset_params['classes']), \n",
        "                   pretrained_weights=\"coco\"\n",
        "                   )"
      ],
      "metadata": {
        "id": "hCGVvPPcbJI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training.losses import PPYoloELoss\n",
        "from super_gradients.training.metrics import DetectionMetrics_050\n",
        "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
        "\n",
        "train_params = {\n",
        "    # ENABLING SILENT MODE\n",
        "    'silent_mode': True,\n",
        "    \"average_best_models\":True,\n",
        "    \"warmup_mode\": \"linear_epoch_step\",\n",
        "    \"warmup_initial_lr\": 1e-6,\n",
        "    \"lr_warmup_epochs\": 3,\n",
        "    \"initial_lr\": 5e-4,\n",
        "    \"lr_mode\": \"cosine\",\n",
        "    \"cosine_final_lr_ratio\": 0.1,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"optimizer_params\": {\"weight_decay\": 0.0001},\n",
        "    \"zero_weight_decay_on_bias_and_bn\": True,\n",
        "    \"ema\": True,\n",
        "    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n",
        "    # ONLY TRAINING FOR 10 EPOCHS FOR THIS EXAMPLE NOTEBOOK\n",
        "    \"max_epochs\": 20,\n",
        "    \"mixed_precision\": True,\n",
        "    \"loss\": PPYoloELoss(\n",
        "        use_static_assigner=False,\n",
        "        # NOTE: num_classes needs to be defined here\n",
        "        num_classes=len(dataset_params['classes']),\n",
        "        reg_max=16\n",
        "    ),\n",
        "    \"valid_metrics_list\": [\n",
        "        DetectionMetrics_050(\n",
        "            score_thres=0.1,\n",
        "            top_k_predictions=300,\n",
        "            # NOTE: num_classes needs to be defined here\n",
        "            num_cls=len(dataset_params['classes']),\n",
        "            normalize_targets=True,\n",
        "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
        "                score_threshold=0.01,\n",
        "                nms_top_k=1000,\n",
        "                max_predictions=300,\n",
        "                nms_threshold=0.7\n",
        "            )\n",
        "        )\n",
        "    ],\n",
        "    \"metric_to_watch\": 'mAP@0.50'\n",
        "}"
      ],
      "metadata": {
        "id": "SBJzqQCrbJM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(model=model, \n",
        "              training_params=train_params, \n",
        "              train_loader=train_data, \n",
        "              valid_loader=val_data)"
      ],
      "metadata": {
        "id": "flt8jw3Hbarg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = models.get('yolo_nas_l',\n",
        "                        num_classes=len(dataset_params['classes']),\n",
        "                        checkpoint_path=\"/content/nas_l_run/average_model.pth\")"
      ],
      "metadata": {
        "id": "IgtHMwLDbate"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting an image\n",
        "img_url = '/content/drive/MyDrive/TATA_splitted/train/Images/02845cef-0d05-47b8-bbf7-0611eefac362.jpeg'\n",
        "best_model.predict(img_url, conf=0.39).show()"
      ],
      "metadata": {
        "id": "2n48RSgibavx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "input_video_path = \"/NRrP1S7LxQE.mp4\" \n",
        "output_video_path = \"tata_yolonas_l_detections.mp4\"\n",
        "best_model.to(device).predict(input_video_path).save(output_video_path)"
      ],
      "metadata": {
        "id": "_jUtYZ-DbazI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CL58R-dAJV_0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}